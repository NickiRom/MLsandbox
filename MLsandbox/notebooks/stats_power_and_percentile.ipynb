{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import csv as csv\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from math import sqrt\n",
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename, na_handler={}):\n",
    "    df = pd.read_csv(filename, sep='\\t', na_values={k:v for k, v in na_handler.iteritems() if isinstance(v,int)}, header=False)\n",
    "    return df\n",
    "    \n",
    "def create_target_1tail(df, sample_and_size_cols=[], baseline_col='', col_name='target', p=0.05):\n",
    "    df[col_name] = np.vectorize(poisson_p)(*sample_and_size_cols, cons=baseline_col, p_val=p)\n",
    "    return col_name\n",
    "\n",
    "def add_rate_col(df, event_col='', per_col='', col_name=''):\n",
    "    df[col_name] = df[event_col]/df[per_col]\n",
    "    return col_name\n",
    "\n",
    "def add_lift_col(df, samp_col='', baseline_col='', col_name=''):\n",
    "    df[col_name] = df[event_col]/df[per_col] - 1\n",
    "    return col_name\n",
    "\n",
    "def power_calc(imps = '', baseline_cvr = '', lift = ''):\n",
    "    if imps == '':\n",
    "        if baseline_cvr !='' and lift !='':\n",
    "            imps = 4/((baseline_cvr)*((sqrt(lift)+1)**2))\n",
    "            #print str(int(imps)) + ' or more impressions needed'\n",
    "            try:\n",
    "                return int(imps)\n",
    "            except:\n",
    "                return 10000000000\n",
    "\n",
    "    elif baseline_cvr == '':\n",
    "        if imps !='' and lift !='':\n",
    "            baseline_cvr = 4/((imps)*((sqrt(lift)+1)**2))\n",
    "            print str(baseline_cvr) + ' or higher baseline conversion rate needed'\n",
    "            return baseline_cvr\n",
    "\n",
    "    elif lift == '':\n",
    "        if baseline_cvr !='' and imps !='':\n",
    "            lift = (sqrt(4/(baseline_cvr*imps))-1)**2\n",
    "            print 'Can detect '+ str(int(lift)) + 'x lift'\n",
    "            return int(lift)\n",
    "    else:\n",
    "        imps_needed = 4/((baseline_cvr)*((sqrt(lift)+1)**2)) - imps\n",
    "        print 'Need ' + str(int(imps_needed)) + ' more impressions to reach significance'\n",
    "        return int(imps_needed)\n",
    "\n",
    "def poisson_p(line_cvr, imps, cons, p_val=0.05):\n",
    "    # mu: expected number of conversions\n",
    "    # k: observed number of conversions (list)\n",
    "    # returns the p-value (probability that we'd observe k or greater given H0)\n",
    "    # note: if no conversions have occurred, poisson is bounded by 3/n trials\n",
    "\n",
    "    #if there are no conversions but also too few impressions, do not use this record\n",
    "    imps_needed = power_calc(baseline_cvr = line_cvr, lift = 1000)\n",
    "    if imps_needed > imps: return -1\n",
    "\n",
    "    p = stats.poisson.sf(cons-1,line_cvr*imps)\n",
    "\n",
    "    if p < p_val: return 1\n",
    "    else: return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def percentile_by_group(row, group='advertiser_id', value=''):\n",
    "    dist = df_test[df_test[group] == row[group]][value]\n",
    "    value = row[value]\n",
    "    return stats.percentileofscore(dist, value)\n",
    "\n",
    "'''df_test['ol_percentile']= df_test.apply(lambda row: np.round(percentile_by_group(row, group='advertiser_id', value='pct_overlap'),2), axis=1)\n",
    "df_test['hl_percentile']= df_test.apply(lambda row: np.round(percentile_by_group(row, group='line_id', value='hist_lift'),2), axis=1)\n",
    "df_test['wr_percentile']= df_test.apply(lambda row: np.round(percentile_by_group(row, group='line_id', value='win_rate'),2), axis=1)\n",
    "df_test['pi_percentile']= df_test.apply(lambda row: np.round(percentile_by_group(row, group='advertiser_id', value='popularity_index'),2), axis=1)\n",
    "df_test['bp_percentile']= df_test.apply(lambda row: np.round(percentile_by_group(row, group='advertiser_id', value='avg_bid_price'),2), axis=1)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
