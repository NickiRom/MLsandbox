{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree, ensemble\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/sample_data_cleaned.csv', sep=',', header=0, index_col=0)\n",
    "\n",
    "features = ['site_id', 'strategy_id', 'name', 'goal', 'price', 'avg_bid', 'max_bid', 'win_rate_site', 'win_rate_strat', 'hist_zscore', 'overlap', 'target']\n",
    "df_subset = df[features]\n",
    "\n",
    "#define training and testing set\n",
    "df['is_train'] = np.random.uniform(0,1, len(df)) > 0.25\n",
    "train = df[df['is_train']==True][features]\n",
    "test = df[df['is_train']==False][features]\n",
    "\n",
    "#vectorize the feature set and one-hot encode adv_vertical\n",
    "vec = DictVectorizer(sparse=False)\n",
    "feats_train = train.T.to_dict().values()\n",
    "features_train = vec.fit_transform(feats_train)\n",
    "feats_test = test.T.to_dict().values()\n",
    "features_test = vec.fit_transform(feats_test)\n",
    "\n",
    "#convert back to dataframe and check for null values\n",
    "train = pd.DataFrame(features_train, columns = vec.get_feature_names())\n",
    "test = pd.DataFrame(features_test, columns = vec.get_feature_names())\n",
    "\n",
    "x_train = train.drop(['target'], axis = 1)\n",
    "y_train = train['target']\n",
    "x_test = test.drop(['target'], axis = 1)\n",
    "y_test = test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.986 \n",
      "\n",
      "train accuracy: 0.969 \n",
      "\n",
      "oob score: 0.969 \n",
      "\n",
      "avg_bid: 0.0578468762968\n",
      " goal: 0.0244124363884\n",
      " hist_zscore: 0.372561468687\n",
      " max_bid: 0.0190890046501\n",
      " name=Andrew: 0.0138828653585\n",
      " name=Edward: 0.0759293160668\n",
      " name=Ian: 0.00107545524508\n",
      " name=Josie: 0.00289150256529\n",
      " name=Lori: 0.0\n",
      " name=Nicole: 9.74055809528e-05\n",
      " name=Travis: 0.00260494499071\n",
      " overlap: 0.257049894484\n",
      " price: 0.0516344433055\n",
      " site_id: 0.0270675665029\n",
      " strategy_id: 0.053724778798\n",
      " win_rate_site: 0.018005041491\n",
      " win_rate_strat: 0.0221269995894\n",
      "\n",
      "cross-validation scores: 0.982456140351, 0.988235294118, 0.988235294118 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = ensemble.RandomForestClassifier(max_features='sqrt', max_depth=6, min_samples_leaf=20, n_estimators=100, oob_score=True).fit(x_train, y_train)\n",
    "print \"test accuracy: %0.3f \\n\" % rf.score(x_test, y_test)\n",
    "print \"train accuracy: %0.3f \\n\" % rf.score(x_train, y_train)\n",
    "print \"oob score: %0.3f \\n\" % rf.oob_score_\n",
    "print ' '.join([x[0] + ': ' + str(x[1]) + '\\n' for x in zip(x_train.columns, rf.feature_importances_)])\n",
    "print \"cross-validation scores: %s \\n\" % ', '.join([str(x) for x in cross_val_score(rf, x_test,y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nromano/RadiumOne/Python/MLsandbox/venv/lib/python2.7/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-52538a12313c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sqrt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moob_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"test accuracy: %0.3f \\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"train accuracy: %0.3f \\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nromano/RadiumOne/Python/MLsandbox/venv/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \"\"\"\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nromano/RadiumOne/Python/MLsandbox/venv/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nromano/RadiumOne/Python/MLsandbox/venv/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "'''\n",
    "#vectorize the feature set and hot encode adv_vertical\n",
    "vec = DictVectorizer(sparse=False)\n",
    "feats= df_subset.T.to_dict().values()\n",
    "features_coded = vec.fit_transform(feats)\n",
    "\n",
    "#convert back to dataframe and check for null values\n",
    "features_df = pd.DataFrame(features_coded, columns = vec.get_feature_names())'''\n",
    "df_subset.dropna(inplace=True)\n",
    "\n",
    "for train_index, test_index in kf.split(df_subset):\n",
    "    x_train, x_test = features_df.loc[train_index, feature_cols], features_df.loc[test_index, feature_cols]\n",
    "    y_train, y_test = features_df.loc[train_index, 'target'], features_df.loc[test_index, 'target']\n",
    "    \n",
    "    rf = ensemble.RandomForestClassifier(max_features='sqrt', max_depth=6, min_samples_leaf=20, n_estimators=100, oob_score=True).fit(x_train, y_train)\n",
    "    print \"test accuracy: %0.3f \\n\" % rf.score(x_test, y_test)\n",
    "    print \"train accuracy: %0.3f \\n\" % rf.score(x_train, y_train)\n",
    "    print \"oob score: %0.3f \\n\" % rf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_importances = []\n",
    "for i, est_tree in enumerate(rf.estimators_):\n",
    "    feature_importances.append(numpy.append(est_tree.feature_importances_, est_tree.score(x_test, y_test)))\n",
    "\n",
    "fig = figure(1, figsize=(9,6))\n",
    "ax = fig.add_subplot(111)\n",
    "bp = ax.boxplot(imp_by_feat)\n",
    "_ = ax.set_xticklabels(features, rotation=90)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
