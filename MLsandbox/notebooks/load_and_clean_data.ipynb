{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nromano/RadiumOne/Python/MLsandbox/venv/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/nromano/RadiumOne/Python/MLsandbox/venv/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from importlib import import_module\n",
    "from MLsandbox import model_search_builder as msb  # import msb tools (developed by Nicole)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>strategy_id</th>\n",
       "      <th>list_type</th>\n",
       "      <th>line_id</th>\n",
       "      <th>adv_id</th>\n",
       "      <th>adv_vertical</th>\n",
       "      <th>name</th>\n",
       "      <th>goal</th>\n",
       "      <th>price</th>\n",
       "      <th>limit</th>\n",
       "      <th>...</th>\n",
       "      <th>win_rate_site</th>\n",
       "      <th>win_rate_strat</th>\n",
       "      <th>cvr_strat</th>\n",
       "      <th>cvr</th>\n",
       "      <th>line_cvr</th>\n",
       "      <th>hist_zscore</th>\n",
       "      <th>overlap</th>\n",
       "      <th>target</th>\n",
       "      <th>win_rate_site_table</th>\n",
       "      <th>win_rate_strat_table</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82932</td>\n",
       "      <td>313729</td>\n",
       "      <td>testing</td>\n",
       "      <td>20049</td>\n",
       "      <td>206.0</td>\n",
       "      <td>Travel</td>\n",
       "      <td>Nicole</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.95</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423778</td>\n",
       "      <td>0.111431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.708366</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0</td>\n",
       "      <td>0.450094</td>\n",
       "      <td>0.249479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90474</td>\n",
       "      <td>313729</td>\n",
       "      <td>testing</td>\n",
       "      <td>20049</td>\n",
       "      <td>206.0</td>\n",
       "      <td>Travel</td>\n",
       "      <td>Nicole</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.95</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163010</td>\n",
       "      <td>0.111431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.188635</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0</td>\n",
       "      <td>0.158050</td>\n",
       "      <td>0.249479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92345</td>\n",
       "      <td>313729</td>\n",
       "      <td>testing</td>\n",
       "      <td>20049</td>\n",
       "      <td>206.0</td>\n",
       "      <td>Travel</td>\n",
       "      <td>Nicole</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.95</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318358</td>\n",
       "      <td>0.111431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.503285</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0</td>\n",
       "      <td>0.360591</td>\n",
       "      <td>0.249479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92415</td>\n",
       "      <td>313729</td>\n",
       "      <td>testing</td>\n",
       "      <td>20049</td>\n",
       "      <td>206.0</td>\n",
       "      <td>Travel</td>\n",
       "      <td>Nicole</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.95</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133199</td>\n",
       "      <td>0.111431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.153628</td>\n",
       "      <td>0.004614</td>\n",
       "      <td>0</td>\n",
       "      <td>0.113717</td>\n",
       "      <td>0.249479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92425</td>\n",
       "      <td>313729</td>\n",
       "      <td>testing</td>\n",
       "      <td>20049</td>\n",
       "      <td>206.0</td>\n",
       "      <td>Travel</td>\n",
       "      <td>Nicole</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.95</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.111431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.091378</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019308</td>\n",
       "      <td>0.249479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   site_id  strategy_id list_type  line_id  adv_id adv_vertical    name  goal  \\\n",
       "0    82932       313729   testing    20049   206.0       Travel  Nicole   0.0   \n",
       "1    90474       313729   testing    20049   206.0       Travel  Nicole   0.0   \n",
       "2    92345       313729   testing    20049   206.0       Travel  Nicole   0.0   \n",
       "3    92415       313729   testing    20049   206.0       Travel  Nicole   0.0   \n",
       "4    92425       313729   testing    20049   206.0       Travel  Nicole   0.0   \n",
       "\n",
       "   price    limit          ...           win_rate_site  win_rate_strat  \\\n",
       "0   3.95  10000.0          ...                0.423778        0.111431   \n",
       "1   3.95  10000.0          ...                0.163010        0.111431   \n",
       "2   3.95  10000.0          ...                0.318358        0.111431   \n",
       "3   3.95  10000.0          ...                0.133199        0.111431   \n",
       "4   3.95  10000.0          ...                0.379310        0.111431   \n",
       "\n",
       "   cvr_strat       cvr  line_cvr  hist_zscore   overlap  target  \\\n",
       "0        0.0  0.001197       0.0     2.708366  0.001066       0   \n",
       "1        0.0  0.001239       0.0     1.188635  0.000703       0   \n",
       "2        0.0  0.000729       0.0     1.503285  0.000873       0   \n",
       "3        0.0  0.005894       0.0    35.153628  0.004614       0   \n",
       "4        0.0  0.000000       0.0    -0.091378  0.000344       0   \n",
       "\n",
       "   win_rate_site_table  win_rate_strat_table  \n",
       "0             0.450094              0.249479  \n",
       "1             0.158050              0.249479  \n",
       "2             0.360591              0.249479  \n",
       "3             0.113717              0.249479  \n",
       "4             0.019308              0.249479  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/sample_data.csv', sep=',', header=0, index_col=0)\n",
    "\n",
    "# rename the target variable, \"target_variable\", to be called \"target\" so msb module will recognize the output variable\n",
    "df.rename(columns={'target_variable':'target'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for data imbalance\n",
    "\n",
    "In model_search_builder.py, you'll find three functions to help with data exploration: success_breakdown, find_nan, and fill_nan_deterministic\n",
    "\n",
    "**success_breakdown(df, by_column='', nan_breakdown=False):** shows the number of successes and failures by value for a particular column.  \n",
    "\n",
    "- This helps you determine whether you have an unbalanced dataset (e.g. if fewer than 10% of your target labels are classified as \"success\").  If this is the case, I recommend reading https://www3.nd.edu/~dial/publications/chawla2005data.pdf\n",
    "- You can also stratify the success breakdown by one of the categorical variables, such as advertiser vertical, to ensure you aren't introducing systematic bias in the training set. \n",
    "\n",
    "#### Print the breakdown of positive and negative training samples and save examples of the positive and negative training sets to variables pos, neg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good: 53 test: 1945\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pos, neg = msb.success_breakdown(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now check for target label imbalance that is specific to certain features\n",
    "\n",
    "For example, below we see that advertiser 48 has 360 sites and none have reached the good list.  In this case, we are looking for signals that will hold true across different advertisers. Is there a source of systematic bias in this training set?  If we train with almost all successes belonging to advertiser 658, we may overfit our model to that example.  It is clear that we need a larger training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206.0// good: 4 test: 108\n",
      "1525.0// good: 0 test: 68\n",
      "1831.0// good: 0 test: 201\n",
      "658.0// good: 18 test: 241\n",
      "915.0// good: 0 test: 46\n",
      "48.0// good: 0 test: 360\n",
      "1454.0// good: 20 test: 240\n",
      "65.0// good: 1 test: 108\n",
      "461.0// good: 0 test: 60\n",
      "2717.0// good: 0 test: 8\n",
      "2795.0// good: 0 test: 8\n",
      "752.0// good: 5 test: 142\n",
      "1234.0// good: 4 test: 88\n",
      "1631.0// good: 1 test: 187\n",
      "834.0// good: 0 test: 66\n",
      "1906.0// good: 0 test: 14\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we don't want to catch the groups for this one, so set equal to a throwaway variable\n",
    "_ = msb.success_breakdown(df, by_column='adv_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle missing data\n",
    "\n",
    "**find_nan(df): ** shows the number of missing values for each feature\n",
    "\n",
    "From the information below, there may be a need to impute values or drop columns like win_rate_strat and cvr_strat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tname has 86 empty rows (4%)\n",
      "\twin_rate_site has 388 empty rows (19%)\n",
      "\twin_rate_strat has 988 empty rows (49%)\n",
      "\tcvr_strat has 988 empty rows (49%)\n",
      "\n",
      "\n",
      "Complete features: site_id, strategy_id, list_type, line_id, adv_id, adv_vertical, goal, price, limit, avg_bid, max_bid, impressions, conversions, avg_imps_site, stdev_imps_site, cvr, line_cvr, hist_zscore, overlap, target, win_rate_site_table, win_rate_strat_table\n",
      "\n"
     ]
    }
   ],
   "source": [
    "msb.find_nan(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: drop the rows\n",
    "\n",
    "This isn't ideal, but if you have enough data and your source of missing values doesn't introduce bias, you can simply drop the rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tname has 79 empty rows (4%)\n",
      "\twin_rate_strat has 770 empty rows (47%)\n",
      "\tcvr_strat has 770 empty rows (47%)\n",
      "\n",
      "\n",
      "Complete features: site_id, strategy_id, list_type, line_id, adv_id, adv_vertical, goal, price, limit, avg_bid, max_bid, impressions, conversions, avg_imps_site, stdev_imps_site, win_rate_site, cvr, line_cvr, hist_zscore, overlap, target, win_rate_site_table, win_rate_strat_table\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dropped = df.dropna(axis = 0, how = 'any', subset = ['win_rate_site'])\n",
    "msb.find_nan(df_dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Deterministic imputation\n",
    "\n",
    "In some cases, we can use deterministic clues to fill in missing data.\n",
    "\n",
    "For instance, we are missing optimizer names for some strategies.  If we can assume all strategies for a single advertiser is always handled by the same optimizer, we can use other strategies under that advertiser to infer the correct optimizer name.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling name by adv_id: 86 rows have been filled.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = msb.fill_nan_deterministic(df, fill_column='name', batch_by='adv_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 3: Unique-value Imputation\n",
    "\n",
    "In other cases, we want to assume a specific value for missing data to simply indicate that the value is unknown.  This is often an acceptable method when using neural nets.\n",
    "\n",
    "Note: it's common to encode missing information as a -1, or something else that is an impossible value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twin_rate_site has 388 empty rows (19%)\n",
      "\tcvr_strat has 988 empty rows (49%)\n",
      "\n",
      "\n",
      "Complete features: site_id, strategy_id, list_type, line_id, adv_id, adv_vertical, name, goal, price, limit, avg_bid, max_bid, impressions, conversions, avg_imps_site, stdev_imps_site, win_rate_strat, cvr, line_cvr, hist_zscore, overlap, target, win_rate_site_table, win_rate_strat_table\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df[['win_rate_strat']] = df[['win_rate_strat']].fillna(value=-1)\n",
    "msb.find_nan(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 4: Interpolation\n",
    "\n",
    "Often, we have to make an educated guess\n",
    "\n",
    "You can impute values according to the mean, median or mode:\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Imputer.html\n",
    "\n",
    "Note: only use the mean if the prior distribution on the value is approximately normally distributed (most of your values center around a mean)!  In cases of high skew, use the median or mode instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twin_rate_site has 388 empty rows (19%)\n",
      "\n",
      "\n",
      "Complete features: site_id, strategy_id, list_type, line_id, adv_id, adv_vertical, name, goal, price, limit, avg_bid, max_bid, impressions, conversions, avg_imps_site, stdev_imps_site, win_rate_strat, cvr_strat, cvr, line_cvr, hist_zscore, overlap, target, win_rate_site_table, win_rate_strat_table\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# build an imputer that takes the mean value of each feature as the imputation value\n",
    "# and apply it to the columns with missing data\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "df[['cvr_strat']] = imp.fit_transform(df[['cvr_strat']]) \n",
    "\n",
    "# check again for any NaN values\n",
    "msb.find_nan(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to use the most common value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Complete features: site_id, strategy_id, list_type, line_id, adv_id, adv_vertical, name, goal, price, limit, avg_bid, max_bid, impressions, conversions, avg_imps_site, stdev_imps_site, win_rate_site, win_rate_strat, cvr_strat, cvr, line_cvr, hist_zscore, overlap, target, win_rate_site_table, win_rate_strat_table\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['win_rate_site'].fillna(df['win_rate_site'].value_counts().idxmax(), inplace = True)\n",
    "msb.find_nan(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 5: kNN imputation\n",
    "\n",
    "Fill values based on similar records\n",
    "\n",
    "This method is computationally expensive, but will yield the best results.  It looks at k records that have similar features and target labels, and then finds a reasonable value for the missing feature.\n",
    "\n",
    "The following package attempts to do this, but is incomplete.  You will have to write your own algorithm:\n",
    "https://pypi.python.org/pypi/fancyimpute/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 6: De-noising autoencoder\n",
    "\n",
    "Finally, you can use an autoencoder: http://stackoverflow.com/questions/32407621/impute-multiple-missing-values-in-a-feature-vector\n",
    "\n",
    "de-noising autoencoders for neural nets:  http://deeplearning.net/tutorial/dA.html#autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now save the cleaned data as a .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('../data/sample_data_cleaned.csv', header = True, index = True, sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For a beginner's guide to imputation methods:\n",
    "http://www.jmlr.org/papers/volume8/saar-tsechansky07a/saar-tsechansky07a.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
